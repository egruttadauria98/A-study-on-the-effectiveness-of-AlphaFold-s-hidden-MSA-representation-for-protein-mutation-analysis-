{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openfold Colab adaptation\n",
    "\n",
    "This notebook is a modification of the OpenFold Colab notebook: https://colab.research.google.com/github/aqlaboratory/openfold/blob/main/notebooks/OpenFold.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "# A filthy hack to avoid slow Linear layer initialization\n",
    "import openfold.model.primitives\n",
    "\n",
    "def __default_linear_init__(self, *args, **kwargs):\n",
    "    return torch.nn.Linear.__init__(\n",
    "      self, \n",
    "      *args[:2], \n",
    "      **{k:v for k,v in kwargs.items() if k == \"bias\"}\n",
    "    )\n",
    "\n",
    "openfold.model.primitives.Linear.__init__ = __default_linear_init__\n",
    "\n",
    "from openfold import config\n",
    "from openfold.data import feature_pipeline\n",
    "from openfold.data import data_pipeline\n",
    "from openfold.model import model\n",
    "from openfold.utils.import_weights import import_jax_weights_\n",
    "from openfold.utils.tensor_utils import tensor_tree_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _placeholder_template_feats(num_templates_, num_res_):\n",
    "  return {\n",
    "      'template_aatype': torch.zeros(num_templates_, num_res_, 22).long(),\n",
    "      'template_all_atom_positions': torch.zeros(num_templates_, num_res_, 37, 3),\n",
    "      'template_all_atom_mask': torch.zeros(num_templates_, num_res_, 37),\n",
    "      'template_domain_names': torch.zeros(num_templates_),\n",
    "      'template_sum_probs': torch.zeros(num_templates_, 1),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data_pickle/deletion_matrices.pickle\", 'rb') as f:\n",
    "    deletion_matrices = pickle.load(f)\n",
    "\n",
    "with open(\"../data_pickle/msas.pickle\", 'rb') as f:\n",
    "    msas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_templates = 1 \n",
    "num_res = len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "feature_dict.update(data_pipeline.make_sequence_features(sequence, 'test', num_res))\n",
    "feature_dict.update(data_pipeline.make_msa_features(msas, deletion_matrices=deletion_matrices))\n",
    "feature_dict.update(_placeholder_template_feats(num_templates, num_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filepath = \"msa_arr.pickle\"\n",
    "output_dir = \"./../data_pickle\"\n",
    "msa_output_path = os.path.join(output_dir, filepath)\n",
    "with open(msa_output_path, 'wb') as f:\n",
    "    pickle.dump(feature_dict['msa'], f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_set = \"OpenFold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.model_config(model_name)\n",
    "openfold_model = model.AlphaFold(cfg)\n",
    "openfold_model = openfold_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENFOLD_PARAMS_DIR = './openfold/resources/openfold_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(weight_set == \"OpenFold\"):\n",
    "  model_name_spl = model_name.split(\"_\")\n",
    "\n",
    "  if(model_name_spl[-1] == \"ptm\"):\n",
    "    of_model_name = \"finetuning_ptm_2.pt\"\n",
    "    \n",
    "  else:\n",
    "    of_model_name = f\"finetuning_{model_name_spl[-1]}.pt\"\n",
    "    \n",
    "  params_name = os.path.join(\n",
    "    OPENFOLD_PARAMS_DIR,\n",
    "    of_model_name\n",
    "  )\n",
    "\n",
    "  d = torch.load(params_name)\n",
    "  openfold_model.load_state_dict(d)\n",
    "else:\n",
    "  raise ValueError(f\"Invalid weight set: {weight_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfold_model = openfold_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elio/Desktop/Thesis-MSc/openfold_model/openfold/data/feature_pipeline.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k: torch.tensor(v) for k, v in np_example.items() if k in features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "2788110\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "2788110\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "2788110\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "2788110\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n"
     ]
    }
   ],
   "source": [
    "pipeline = feature_pipeline.FeaturePipeline(cfg.data)\n",
    " \n",
    "processed_feature_dict = pipeline.process_features(\n",
    "  feature_dict, mode='predict'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aatype', 'residue_index', 'seq_length', 'template_aatype', 'template_all_atom_positions', 'template_all_atom_mask', 'template_sum_probs', 'seq_mask', 'msa_mask', 'msa_row_mask', 'template_mask', 'template_pseudo_beta', 'template_pseudo_beta_mask', 'template_torsion_angles_sin_cos', 'template_alt_torsion_angles_sin_cos', 'template_torsion_angles_mask', 'atom14_atom_exists', 'residx_atom14_to_atom37', 'residx_atom37_to_atom14', 'atom37_atom_exists', 'extra_msa', 'extra_msa_mask', 'extra_msa_row_mask', 'bert_mask', 'true_msa', 'extra_has_deletion', 'extra_deletion_value', 'msa_feat', 'target_feat'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 286, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_feature_dict['true_msa'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_feature_dict = tensor_tree_map(\n",
    "    lambda t: t.cuda(), processed_feature_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 286, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_feature_dict['true_msa'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "  prediction_result = openfold_model(processed_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['msa', 'pair', 'single', 'sm', 'final_atom_positions', 'final_atom_mask', 'final_affine_tensor', 'lddt_logits', 'plddt', 'distogram_logits', 'masked_msa_logits', 'experimentally_resolved_logits'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.1191,  -9.6091,  10.6376,  ...,  16.7106,   5.8943,  -9.3006],\n",
       "         [  1.4778,  -0.0605,   9.2424,  ...,  14.3378,   8.9431,  -8.1625],\n",
       "         [ -3.0234, -12.3100, -13.6958,  ...,   9.7739,   6.6718,  -3.3194],\n",
       "         ...,\n",
       "         [  9.3769,  10.1555, -11.3802,  ...,  -7.1300,   7.1486,   7.5885],\n",
       "         [ 10.6756, -20.5260, -15.4468,  ..., -12.4990,  -9.3852,   0.9390],\n",
       "         [  3.1308,  -7.8135,  -6.2527,  ...,  -1.1047,  -1.4711,  -6.7019]],\n",
       "\n",
       "        [[  5.4426,  -2.8225,  -4.8795,  ...,  -2.8427,  -6.8015,   3.0237],\n",
       "         [  5.8724,  -3.6131,  -5.7323,  ...,  -1.6076,  -7.6941,  -0.2041],\n",
       "         [  3.1117,  -1.3960,  -5.9726,  ...,  -2.0690,  -8.4099,   1.6113],\n",
       "         ...,\n",
       "         [  5.0194,  -4.6451,  -7.6387,  ...,  -1.3770,  -7.1926,   0.7363],\n",
       "         [  5.7854,  -5.0206,  -7.0606,  ...,  -2.5019,  -6.1591,   0.6487],\n",
       "         [  5.3092,  -4.4249,  -9.3564,  ...,  -2.2320,  -7.3628,   2.4500]],\n",
       "\n",
       "        [[  3.5424,  -2.2098,  -5.3928,  ...,  -1.8931,  -3.8775,   3.8768],\n",
       "         [  3.4899,  -3.8590,  -3.2453,  ...,  -0.8642,  -5.5727,  -0.6432],\n",
       "         [  2.4415,  -3.0815,  -5.5882,  ...,  -0.7365,  -5.4110,   0.1197],\n",
       "         ...,\n",
       "         [  4.2918,  -5.0725,  -6.5498,  ...,  -1.4511,  -9.6153,   0.6314],\n",
       "         [  1.9698,  -4.5153,  -1.9979,  ...,  -2.9931,  -8.4361,   0.2098],\n",
       "         [  5.7062,  -3.9144,  -5.3493,  ...,  -3.7095,  -6.3410,   1.8074]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  4.3094,  -2.3444,  -8.5271,  ...,  -4.0456,  -3.0300,   4.3729],\n",
       "         [  5.1509,  -4.0713,  -5.4465,  ...,  -2.4418,  -5.5419,   1.4894],\n",
       "         [  4.2486,  -3.0007,  -7.5531,  ...,  -2.3458,  -5.3349,   2.1130],\n",
       "         ...,\n",
       "         [  5.4027,  -1.7934, -10.1492,  ...,  -0.2494,  -6.6076,   2.4960],\n",
       "         [  5.4087,  -2.1567,  -8.6660,  ...,  -2.1433,  -5.3773,   0.2541],\n",
       "         [  5.5847,  -2.6928,  -9.5588,  ...,  -3.5035,  -3.5254,   2.2769]],\n",
       "\n",
       "        [[  5.4619,  -2.6748, -11.7163,  ...,  -8.4519,  -0.9073,   7.3349],\n",
       "         [  5.5062,  -5.7913,  -1.1521,  ...,  -6.6054, -12.4913,   1.6798],\n",
       "         [  1.6786,  -4.9885,  -4.6098,  ...,  -7.3081,  -4.6546,   2.1151],\n",
       "         ...,\n",
       "         [  3.4648,  -1.8917,  -5.0317,  ...,  -2.4113, -11.1561,   1.0622],\n",
       "         [  1.5824,  -2.1104,  -1.8866,  ...,  -4.0380,  -9.8825,   0.5001],\n",
       "         [  3.6244,  -1.0140,  -4.2868,  ...,  -5.1714,  -7.3402,   0.6819]],\n",
       "\n",
       "        [[  7.1087,  -5.4940,  -9.5770,  ...,  -7.6312,   8.0775,   4.4009],\n",
       "         [  3.6202,  -5.0025,  -3.2332,  ...,  -4.5091, -11.8410,  -0.1680],\n",
       "         [  2.9539,  -5.4707,  -1.0207,  ...,  -6.7596,   2.0894,   1.2538],\n",
       "         ...,\n",
       "         [ 13.8611,  -9.7905,  -3.1881,  ...,  -2.1922, -15.4531,   4.2131],\n",
       "         [ 11.2463,   8.7433,  -1.0303,  ...,  -5.5698, -16.1978,   0.9045],\n",
       "         [  2.3279,  -3.5847,  -1.0167,  ...,  -6.8847,  -6.8719,   2.9064]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result['msa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 286, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result['msa'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filepath = \"prediction_result.pickle\"\n",
    "output_dir = \"./../data_pickle\"\n",
    "msa_output_path = os.path.join(output_dir, filepath)\n",
    "with open(msa_output_path, 'wb') as f:\n",
    "    pickle.dump(prediction_result, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 high vs 10 lows mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(sequence, msas, deletion_matrices, filename):\n",
    "\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(data_pipeline.make_sequence_features(sequence, 'test', num_res))\n",
    "    feature_dict.update(data_pipeline.make_msa_features(msas, deletion_matrices=deletion_matrices))\n",
    "    feature_dict.update(_placeholder_template_feats(num_templates, num_res))\n",
    "\n",
    "    cfg = config.model_config(model_name)\n",
    "    openfold_model = model.AlphaFold(cfg)\n",
    "    openfold_model = openfold_model.eval()\n",
    "\n",
    "    if(weight_set == \"OpenFold\"):\n",
    "        model_name_spl = model_name.split(\"_\")\n",
    "\n",
    "        if(model_name_spl[-1] == \"ptm\"):\n",
    "            of_model_name = \"finetuning_ptm_2.pt\"\n",
    "            \n",
    "        else:\n",
    "            of_model_name = f\"finetuning_{model_name_spl[-1]}.pt\"\n",
    "            \n",
    "        params_name = os.path.join(\n",
    "            OPENFOLD_PARAMS_DIR,\n",
    "            of_model_name\n",
    "        )\n",
    "\n",
    "        d = torch.load(params_name)\n",
    "        openfold_model.load_state_dict(d)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid weight set: {weight_set}\")\n",
    "\n",
    "    openfold_model = openfold_model.cuda()\n",
    "\n",
    "    pipeline = feature_pipeline.FeaturePipeline(cfg.data)\n",
    " \n",
    "    processed_feature_dict = pipeline.process_features(\n",
    "        feature_dict, mode='predict'\n",
    "    )\n",
    "\n",
    "    processed_feature_dict = tensor_tree_map(\n",
    "        lambda t: t.cuda(), processed_feature_dict\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction_result = openfold_model(processed_feature_dict)\n",
    "\n",
    "    filename = filename + \".pickle\"\n",
    "    output_dir = \"./../data_pickle/low_and_high_representation\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(prediction_result, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data_pickle/sequences_openfold_dict.pickle\", 'rb') as f:\n",
    "    sequences_openfold_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['low_1', 'low_2', 'low_3', 'low_4', 'low_5', 'low_6', 'low_7', 'low_8', 'low_9', 'low_10', 'high_1', 'high_2', 'high_3', 'high_4', 'high_5', 'high_6', 'high_7', 'high_8', 'high_9', 'high_10'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_openfold_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elio/Desktop/Thesis-MSc/openfold_model/openfold/data/feature_pipeline.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k: torch.tensor(v) for k, v in np_example.items() if k in features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 108\n",
      "0\n",
      "2744834\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 651\n",
      "0\n",
      "2821065\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 545\n",
      "0\n",
      "2736497\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 621\n",
      "0\n",
      "2726898\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "low_2\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 588\n",
      "0\n",
      "2642247\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 521\n",
      "0\n",
      "2632740\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 675\n",
      "0\n",
      "2808027\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 655\n",
      "0\n",
      "2676066\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "low_3\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 95\n",
      "0\n",
      "2799071\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 415\n",
      "0\n",
      "2745634\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 576\n",
      "0\n",
      "2731552\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 228\n",
      "0\n",
      "2806043\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "low_4\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 216\n",
      "0\n",
      "2829104\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 327\n",
      "0\n",
      "2710874\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 123\n",
      "0\n",
      "2769471\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 580\n",
      "0\n",
      "2817280\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "low_5\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 745\n",
      "0\n",
      "2651403\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 815\n",
      "0\n",
      "2727746\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 116\n",
      "0\n",
      "2693797\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 93\n",
      "0\n",
      "2837103\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "low_6\n",
      "\tNo file\n",
      "low_7\n",
      "\tNo file\n",
      "low_8\n",
      "\tNo file\n",
      "low_9\n",
      "\tNo file\n",
      "low_10\n",
      "\tNo file\n",
      "high_1\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 845\n",
      "0\n",
      "2896903\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 131\n",
      "0\n",
      "2719054\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 210\n",
      "0\n",
      "2813756\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 125\n",
      "0\n",
      "2835423\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "high_2\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 844\n",
      "0\n",
      "2728810\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 385\n",
      "0\n",
      "2893668\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 873\n",
      "0\n",
      "2833875\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 816\n",
      "0\n",
      "2744099\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "high_3\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 457\n",
      "0\n",
      "2678258\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 61\n",
      "0\n",
      "2569599\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 899\n",
      "0\n",
      "2794177\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 741\n",
      "0\n",
      "2807244\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "high_4\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 244\n",
      "0\n",
      "2634690\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 579\n",
      "0\n",
      "2834577\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 239\n",
      "0\n",
      "2796256\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 606\n",
      "0\n",
      "2761075\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "high_5\n",
      "\t\tRecycling from configs\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 51\n",
      "0\n",
      "2751681\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 602\n",
      "0\n",
      "2770699\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 572\n",
      "0\n",
      "2859563\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "\tCALLING MSA SAMPLING\n",
      "seed: 562\n",
      "0\n",
      "2851266\n",
      "Dumping pickle at ./../data_pickle/sel_seq.pickle\n",
      "Dumping pickle at ./../data_pickle/not_sel_seq.pickle\n",
      "high_6\n",
      "\tNo file\n",
      "high_7\n",
      "\tNo file\n",
      "high_8\n",
      "\tNo file\n",
      "high_9\n",
      "\tNo file\n",
      "high_10\n",
      "\tNo file\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO: \n",
    "1)Run OpenFold the extract the MSA representation\n",
    "\n",
    "2)Then do correlation of the first row of the representations\n",
    "\n",
    "3)Then, for each first row of the MSA representation,\n",
    "compute the delta elbo (on the model trained with the MSA representation of the original sequence),\n",
    "correlate the delta elbo between the two groups of mutations\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "for mutation_key in sequences_openfold_dict.keys():\n",
    "\n",
    "    print(mutation_key)\n",
    "\n",
    "    if mutation_key in [x.split('.')[0] for x in os.listdir(\"../data_pickle/low_and_high_representation/\")]:\n",
    "        print(\"\\tFile already processed\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "\n",
    "        sequence = sequences_openfold_dict[mutation_key]\n",
    "        \n",
    "        msas_filename = mutation_key + \"_msas.pickle\"\n",
    "\n",
    "        with open(\"../data_pickle/low_and_high_msa/\" + msas_filename, 'rb') as f:\n",
    "            msas = pickle.load(f)\n",
    "\n",
    "\n",
    "        deletion_matrices_filename = mutation_key + \"_deletion_matrices.pickle\"\n",
    "\n",
    "        with open(\"../data_pickle/low_and_high_msa/\" + deletion_matrices_filename, 'rb') as f:\n",
    "            deletion_matrices = pickle.load(f)\n",
    "\n",
    "        \n",
    "        full_pipeline(sequence, msas, deletion_matrices, filename=mutation_key)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\tNo file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between MSA representation (first row only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_output = './../data_pickle/low_and_high_representation'\n",
    "\n",
    "d = dict()\n",
    "\n",
    "for output in os.listdir(folder_output):\n",
    "\n",
    "    output_path = os.path.join(folder_output, output)\n",
    "\n",
    "    with open(output_path, 'rb') as f:\n",
    "        output_representation = pickle.load(f)\n",
    "    \n",
    "    output_name = output.split(\".\")[0]\n",
    "\n",
    "    d[output_name] = output_representation['msa'][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['low_1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['low_3', 'low_4', 'high_3', 'low_2', 'high_2', 'high_5', 'high_1', 'low_1', 'high_4', 'low_5'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_keys = ['low_1', 'low_2', 'low_3', 'low_4', 'low_5', 'high_1', 'high_2', 'high_3', 'high_4', 'high_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = np.zeros((len(ordered_keys), len(ordered_keys)))\n",
    "corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key_i in enumerate(ordered_keys):\n",
    "\n",
    "    representation_i = d[key_i]\n",
    "\n",
    "    for j, key_j in enumerate(ordered_keys):\n",
    "\n",
    "        representation_j = d[key_j]\n",
    "\n",
    "        list_corr = []\n",
    "\n",
    "        for channel in range(256):\n",
    "            list_corr.append(pearsonr(representation_i[:, channel], representation_j[:, channel])[0])\n",
    "            \n",
    "        corr = np.array(list_corr).mean()\n",
    "        corr_matrix[i, j] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98584834, 0.98575235, 0.98198925, 0.98075869,\n",
       "        0.98476074, 0.98251592, 0.98372581, 0.98475337, 0.98532739],\n",
       "       [0.98584834, 1.        , 0.98887337, 0.98659314, 0.98885967,\n",
       "        0.98800684, 0.98837381, 0.98756342, 0.98739574, 0.99019777],\n",
       "       [0.98575235, 0.98887337, 1.        , 0.98994107, 0.98849093,\n",
       "        0.98658999, 0.98648461, 0.98506605, 0.99021396, 0.98812129],\n",
       "       [0.98198925, 0.98659314, 0.98994107, 1.        , 0.98622131,\n",
       "        0.9851351 , 0.98448743, 0.9821114 , 0.98938194, 0.98538096],\n",
       "       [0.98075869, 0.98885967, 0.98849093, 0.98622131, 1.        ,\n",
       "        0.98198308, 0.98524455, 0.98248855, 0.98582942, 0.98536993],\n",
       "       [0.98476074, 0.98800684, 0.98658999, 0.9851351 , 0.98198308,\n",
       "        1.        , 0.98298573, 0.98477118, 0.98641474, 0.99039229],\n",
       "       [0.98251592, 0.98837381, 0.98648461, 0.98448743, 0.98524455,\n",
       "        0.98298573, 1.        , 0.98238478, 0.98435959, 0.98614479],\n",
       "       [0.98372581, 0.98756342, 0.98506605, 0.9821114 , 0.98248855,\n",
       "        0.98477118, 0.98238478, 1.        , 0.98442643, 0.98484471],\n",
       "       [0.98475337, 0.98739574, 0.99021396, 0.98938194, 0.98582942,\n",
       "        0.98641474, 0.98435959, 0.98442643, 1.        , 0.98670881],\n",
       "       [0.98532739, 0.99019777, 0.98812129, 0.98538096, 0.98536993,\n",
       "        0.99039229, 0.98614479, 0.98484471, 0.98670881, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(corr_matrix, xticklabels=ordered_keys, yticklabels=ordered_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean_by_category = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_high = np.zeros((286, 256))\n",
    "sum_low = np.zeros((286, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ordered_keys:\n",
    "\n",
    "    if \"high\" in key:\n",
    "        sum_high += d[key]\n",
    "    else:\n",
    "        sum_low += d[key]\n",
    "\n",
    "d_mean_by_category['high'] = sum_high/5.0\n",
    "d_mean_by_category['low'] = sum_low/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_by_category = np.zeros((2, 2))\n",
    "corr_matrix_by_category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['high', 'low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key_i in enumerate(categories):\n",
    "\n",
    "    representation_i = d_mean_by_category[key_i]\n",
    "\n",
    "    for j, key_j in enumerate(categories):\n",
    "\n",
    "        representation_j = d_mean_by_category[key_j]\n",
    "\n",
    "        list_corr = []\n",
    "\n",
    "        for channel in range(256):\n",
    "            list_corr.append(pearsonr(representation_i[:, channel], representation_j[:, channel])[0])\n",
    "            \n",
    "        corr = np.array(list_corr).mean()\n",
    "        corr_matrix_by_category[i, j] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99715782],\n",
       "       [0.99715782, 1.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b734eb7758abf3393a931433e51bb29d8c11a2cadf78a044dad7bdf5c07010d3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
